{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf3463e2-b82b-4c29-a7a7-d94671dc8a48",
   "metadata": {},
   "source": [
    "Here we train a neural network on data from data_generation_dynamics_simulation and demonstrate quantum error mitigation. Echo-evolution (training data) has time points $t \\in [0,...,\\pi/2]$ and forward-in-time evolution (test data) has time points $ t \\in [0,...,\\pi]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea820106-473f-485f-a586-aebe1c5fa214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from 'c:\\\\Users\\\\miPro\\\\code\\\\Quantum computing\\\\neural_network_error_mitigation\\\\paper_code\\\\functions.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import importlib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import nn_functions\n",
    "importlib.reload(nn_functions)\n",
    "import functions as func\n",
    "importlib.reload(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d2018-b3eb-46f6-a79b-f5ca446f03a5",
   "metadata": {},
   "source": [
    "### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b95092e-15db-4c67-8072-5a82f2b0f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "#new_dir = cwd + '/data_q_000_J_half_h'\n",
    "#new_dir = cwd + '/data_q_003_J_half_h'\n",
    "#new_dir = cwd + '/data_q_007_J_half_h'\n",
    "new_dir = cwd + '/data_q_01_J_half_h'\n",
    "#new_dir = cwd + '/data_q_011_J_half_h'\n",
    "#new_dir = cwd + '/data_q_012_J_half_h'\n",
    "#new_dir = cwd + '/data_q_013_J_half_h'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16afe8b-29f8-4f9f-b1b4-50d251a4c3f3",
   "metadata": {},
   "source": [
    "#### Echo-evolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eae67b0c-afbe-4b2b-8c5b-0eaed50e62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data['data'].shape = (number of initial states, number of time points, noise-free(0) or noisy(1), number of spins)\n",
    "\"\"\"\n",
    "\n",
    "data_name = '/data_t_5'\n",
    "\n",
    "with open(new_dir + data_name + '.pkl', 'rb') as f:\n",
    "    train_data_loaded = pickle.load(f)\n",
    "    \n",
    "del train_data_loaded['parameters']['init state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00bbdc-1f05-4d42-a259-c0591064430a",
   "metadata": {},
   "source": [
    "#### Forward-in-time evolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ce065d0-3e79-46be-8baf-42e27a71fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = '/test_data_10_trotters_T'\n",
    "\n",
    "T_postfix = data_name.split('_')[-1]\n",
    "\n",
    "with open(new_dir + data_name + '.pkl', 'rb') as f:\n",
    "    test_data_loaded = pickle.load(f)\n",
    "    \n",
    "del test_data_loaded['parameters']['init state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2554b38-96ad-4e6e-9a78-045ebb49a39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'J values': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
      " 'backend': QasmSimulator('qasm_simulator'),\n",
      " 'circuit': <qiskit.circuit.quantumcircuit.QuantumCircuit object at 0x00000271B84276D0>,\n",
      " 'coupling map': [[0, 1], [0, 2], [1, 3], [3, 2], [2, 4], [3, 5], [4, 5]],\n",
      " 'h values': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
      " 'num of qubits': 6,\n",
      " 'num of trotters': 10,\n",
      " 'p threshold': 0.8,\n",
      " 'time points': 5,\n",
      " 'total sim time': 3.141592653589793}\n",
      "{'J values': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
      " 'backend': QasmSimulator('qasm_simulator'),\n",
      " 'circuit': <qiskit.circuit.quantumcircuit.QuantumCircuit object at 0x00000271FC76D490>,\n",
      " 'coupling map': [[0, 1], [0, 2], [1, 3], [3, 2], [2, 4], [3, 5], [4, 5]],\n",
      " 'h values': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
      " 'num of qubits': 6,\n",
      " 'num of trotters': 10,\n",
      " 'p threshold': 0.8,\n",
      " 'time points': 20,\n",
      " 'total sim time': 3.141592653589793}\n",
      "Number of operations:\n",
      "OrderedDict([('barrier', 361),\n",
      "             ('cx', 280),\n",
      "             ('rz', 140),\n",
      "             ('rx', 120),\n",
      "             ('measure', 6),\n",
      "             ('initialize', 1)])\n",
      "OrderedDict([('barrier', 361),\n",
      "             ('cx', 280),\n",
      "             ('rz', 140),\n",
      "             ('rx', 120),\n",
      "             ('measure', 6),\n",
      "             ('initialize', 1)])\n",
      "(2400, 5, 2, 6)\n",
      "(100, 20, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(train_data_loaded['parameters'])\n",
    "pprint.pprint(test_data_loaded['parameters'])\n",
    "\n",
    "print(\"Number of operations:\")\n",
    "pprint.pprint(train_data_loaded['parameters']['circuit'].count_ops())\n",
    "pprint.pprint(test_data_loaded['parameters']['circuit'].count_ops())\n",
    "\n",
    "\"\"\"\n",
    "data['data'].shape = (number of initial states, number of time points, noise-free(0) or noisy(1), number of spins)\n",
    "\"\"\"\n",
    "# Echo-evolution data shape\n",
    "print(train_data_loaded['data'].shape)\n",
    "# Forward-in-time-evolution data shape\n",
    "print(test_data_loaded['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3606d53c-c7cc-4614-b8db-2499fc6b2ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (2400, 5, 2, 6)\n",
      "(12000, 6) torch.Size([8000, 6]) torch.Size([2000, 6]) torch.Size([2000, 6])\n",
      "(12000, 6) torch.Size([8000, 6]) torch.Size([2000, 6]) torch.Size([2000, 6])\n",
      "Noisy data vector t:     tensor([-0.2426, -0.0846,  0.0018,  0.0312,  0.0998, -0.1640],\n",
      "       dtype=torch.float64)\n",
      "Noise-free data vector t:  tensor([-0.7606, -0.2776,  0.1232,  0.0790,  0.6360, -0.6960],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert qubit excitation to spin magnetization\n",
    "X = train_data_loaded['data'][:,:,1,:]\n",
    "X = 2*X - 1\n",
    "y = train_data_loaded['data'][:,:,0,:]\n",
    "y = 2*y - 1\n",
    "\n",
    "# Upload time points\n",
    "time_points = np.linspace(0, train_data_loaded['parameters']['total sim time'], train_data_loaded['parameters']['time points'])\n",
    "tn = X.shape[1] # number of time points\n",
    "\n",
    "# Expand data from different data points\n",
    "X_new = []\n",
    "for k in range(X.shape[1]):\n",
    "    X_new += [*X[:,k,:]]\n",
    "X_new = np.array(X_new)\n",
    "X = X_new\n",
    "\n",
    "y_new = []\n",
    "for k in range(y.shape[1]):\n",
    "    y_new += [*y[:,k,:]]\n",
    "y_new = np.array(y_new)\n",
    "y = y_new\n",
    "\n",
    "# Divide data into train and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1666)\n",
    "X_train_val = torch.from_numpy(X_train_val)\n",
    "X_test  = torch.from_numpy(X_test)\n",
    "y_train_val = torch.from_numpy(y_train_val)\n",
    "y_test  = torch.from_numpy(y_test)\n",
    "\n",
    "# Divide training data into training and validation sets\n",
    "valid_size = 0.2\n",
    "num_train_val = len(X_train_val)\n",
    "indices = list(range(num_train_val))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train_val))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "X_train = X_train_val[train_idx]    \n",
    "y_train = y_train_val[train_idx]\n",
    "\n",
    "X_valid = X_train_val[valid_idx]    \n",
    "y_valid = y_train_val[valid_idx]\n",
    "    \n",
    "print(\"data shape: \", train_data_loaded['data'].shape)\n",
    "print(X.shape, X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y.shape, y_train.shape, y_valid.shape, y_test.shape)\n",
    "\n",
    "k = 0\n",
    "\n",
    "print(\"Noisy data vector t:    \", X_train[k])\n",
    "print(\"Noise-free data vector t: \", y_train[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d3d8c-48ff-4621-b6d5-2c7690cdb4cb",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1a2230-e9f9-4edf-9453-b725c001848c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 200]                 1,400\n",
      "├─LeakyReLU: 1-2                         [-1, 200]                 --\n",
      "├─Linear: 1-3                            [-1, 200]                 40,200\n",
      "├─LeakyReLU: 1-4                         [-1, 200]                 --\n",
      "├─Linear: 1-5                            [-1, 6]                   1,206\n",
      "├─Tanh: 1-6                              [-1, 6]                   --\n",
      "==========================================================================================\n",
      "Total params: 42,806\n",
      "Trainable params: 42,806\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.04\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.17\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miPro\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 200]                 1,400\n",
       "├─LeakyReLU: 1-2                         [-1, 200]                 --\n",
       "├─Linear: 1-3                            [-1, 200]                 40,200\n",
       "├─LeakyReLU: 1-4                         [-1, 200]                 --\n",
       "├─Linear: 1-5                            [-1, 6]                   1,206\n",
       "├─Tanh: 1-6                              [-1, 6]                   --\n",
       "==========================================================================================\n",
       "Total params: 42,806\n",
       "Trainable params: 42,806\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.16\n",
       "Estimated Total Size (MB): 0.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nn_functions\n",
    "importlib.reload(nn_functions)\n",
    "\n",
    "D_in = X_train[0].shape[0]\n",
    "D_hidden = 200\n",
    "\n",
    "model     = nn_functions.generate_onelayer_model(D_in, D_hidden, out_f='tanh')\n",
    "model_name = f'spin_model_t{tn}_Dh_{D_hidden}_{T_postfix}'\n",
    "\n",
    "if not os.path.isdir(new_dir + '/' + model_name):\n",
    "    os.mkdir(new_dir + '/' + model_name)\n",
    "\n",
    "summary(model, (6, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a71e7-b1dd-4f00-a6e5-f9c1f7a38fe6",
   "metadata": {},
   "source": [
    "### Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "455b78da-64f8-4274-b039-d9751b2328b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "lr_0 = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_0)\n",
    "criterion = nn.MSELoss()\n",
    "N_batches = 80\n",
    "batch_size = int(X_train.shape[0]/N_batches)\n",
    "print(batch_size)\n",
    "epochs = 100     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1f4a2ae3-3564-48f6-bfff-cd56d992264f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.710658 \tValidation Loss: 0.683290\n",
      "Validation loss decreased (inf --> 0.683290).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.665697 \tValidation Loss: 0.637568\n",
      "Validation loss decreased (0.683290 --> 0.637568).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.619564 \tValidation Loss: 0.591437\n",
      "Validation loss decreased (0.637568 --> 0.591437).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.573997 \tValidation Loss: 0.546730\n",
      "Validation loss decreased (0.591437 --> 0.546730).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.531487 \tValidation Loss: 0.506698\n",
      "Validation loss decreased (0.546730 --> 0.506698).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.493824 \tValidation Loss: 0.472116\n",
      "Validation loss decreased (0.506698 --> 0.472116).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.461525 \tValidation Loss: 0.442585\n",
      "Validation loss decreased (0.472116 --> 0.442585).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.433767 \tValidation Loss: 0.417279\n",
      "Validation loss decreased (0.442585 --> 0.417279).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.409673 \tValidation Loss: 0.395111\n",
      "Validation loss decreased (0.417279 --> 0.395111).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.388464 \tValidation Loss: 0.375538\n",
      "Validation loss decreased (0.395111 --> 0.375538).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.369612 \tValidation Loss: 0.357950\n",
      "Validation loss decreased (0.375538 --> 0.357950).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.352718 \tValidation Loss: 0.342127\n",
      "Validation loss decreased (0.357950 --> 0.342127).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.337479 \tValidation Loss: 0.327822\n",
      "Validation loss decreased (0.342127 --> 0.327822).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.323710 \tValidation Loss: 0.314877\n",
      "Validation loss decreased (0.327822 --> 0.314877).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.311228 \tValidation Loss: 0.303304\n",
      "Validation loss decreased (0.314877 --> 0.303304).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.300010 \tValidation Loss: 0.292939\n",
      "Validation loss decreased (0.303304 --> 0.292939).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.289976 \tValidation Loss: 0.283623\n",
      "Validation loss decreased (0.292939 --> 0.283623).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.281107 \tValidation Loss: 0.275436\n",
      "Validation loss decreased (0.283623 --> 0.275436).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.273276 \tValidation Loss: 0.268342\n",
      "Validation loss decreased (0.275436 --> 0.268342).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.266476 \tValidation Loss: 0.262295\n",
      "Validation loss decreased (0.268342 --> 0.262295).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.260638 \tValidation Loss: 0.256918\n",
      "Validation loss decreased (0.262295 --> 0.256918).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.255509 \tValidation Loss: 0.252303\n",
      "Validation loss decreased (0.256918 --> 0.252303).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.250996 \tValidation Loss: 0.248274\n",
      "Validation loss decreased (0.252303 --> 0.248274).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.247136 \tValidation Loss: 0.244861\n",
      "Validation loss decreased (0.248274 --> 0.244861).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.243958 \tValidation Loss: 0.241964\n",
      "Validation loss decreased (0.244861 --> 0.241964).  Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 0.241397 \tValidation Loss: 0.239606\n",
      "Validation loss decreased (0.241964 --> 0.239606).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.239257 \tValidation Loss: 0.237648\n",
      "Validation loss decreased (0.239606 --> 0.237648).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.237544 \tValidation Loss: 0.235993\n",
      "Validation loss decreased (0.237648 --> 0.235993).  Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.236163 \tValidation Loss: 0.234656\n",
      "Validation loss decreased (0.235993 --> 0.234656).  Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.235039 \tValidation Loss: 0.233553\n",
      "Validation loss decreased (0.234656 --> 0.233553).  Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 0.234108 \tValidation Loss: 0.232606\n",
      "Validation loss decreased (0.233553 --> 0.232606).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.233288 \tValidation Loss: 0.231763\n",
      "Validation loss decreased (0.232606 --> 0.231763).  Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 0.232578 \tValidation Loss: 0.231019\n",
      "Validation loss decreased (0.231763 --> 0.231019).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.231938 \tValidation Loss: 0.230364\n",
      "Validation loss decreased (0.231019 --> 0.230364).  Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 0.231362 \tValidation Loss: 0.229795\n",
      "Validation loss decreased (0.230364 --> 0.229795).  Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 0.230830 \tValidation Loss: 0.229227\n",
      "Validation loss decreased (0.229795 --> 0.229227).  Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 0.230330 \tValidation Loss: 0.228726\n",
      "Validation loss decreased (0.229227 --> 0.228726).  Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 0.229862 \tValidation Loss: 0.228242\n",
      "Validation loss decreased (0.228726 --> 0.228242).  Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 0.229416 \tValidation Loss: 0.227806\n",
      "Validation loss decreased (0.228242 --> 0.227806).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.229018 \tValidation Loss: 0.227377\n",
      "Validation loss decreased (0.227806 --> 0.227377).  Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 0.228623 \tValidation Loss: 0.227016\n",
      "Validation loss decreased (0.227377 --> 0.227016).  Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 0.228226 \tValidation Loss: 0.226619\n",
      "Validation loss decreased (0.227016 --> 0.226619).  Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 0.227860 \tValidation Loss: 0.226259\n",
      "Validation loss decreased (0.226619 --> 0.226259).  Saving model ...\n",
      "Epoch: 44 \tTraining Loss: 0.227499 \tValidation Loss: 0.225922\n",
      "Validation loss decreased (0.226259 --> 0.225922).  Saving model ...\n",
      "Epoch: 45 \tTraining Loss: 0.227136 \tValidation Loss: 0.225551\n",
      "Validation loss decreased (0.225922 --> 0.225551).  Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 0.226744 \tValidation Loss: 0.225145\n",
      "Validation loss decreased (0.225551 --> 0.225145).  Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 0.226360 \tValidation Loss: 0.224783\n",
      "Validation loss decreased (0.225145 --> 0.224783).  Saving model ...\n",
      "Epoch: 48 \tTraining Loss: 0.225931 \tValidation Loss: 0.224367\n",
      "Validation loss decreased (0.224783 --> 0.224367).  Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 0.225489 \tValidation Loss: 0.223968\n",
      "Validation loss decreased (0.224367 --> 0.223968).  Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.225030 \tValidation Loss: 0.223584\n",
      "Validation loss decreased (0.223968 --> 0.223584).  Saving model ...\n",
      "Epoch: 51 \tTraining Loss: 0.224538 \tValidation Loss: 0.223086\n",
      "Validation loss decreased (0.223584 --> 0.223086).  Saving model ...\n",
      "Epoch: 52 \tTraining Loss: 0.224009 \tValidation Loss: 0.222589\n",
      "Validation loss decreased (0.223086 --> 0.222589).  Saving model ...\n",
      "Epoch: 53 \tTraining Loss: 0.223440 \tValidation Loss: 0.222020\n",
      "Validation loss decreased (0.222589 --> 0.222020).  Saving model ...\n",
      "Epoch: 54 \tTraining Loss: 0.222798 \tValidation Loss: 0.221387\n",
      "Validation loss decreased (0.222020 --> 0.221387).  Saving model ...\n",
      "Epoch: 55 \tTraining Loss: 0.222089 \tValidation Loss: 0.220666\n",
      "Validation loss decreased (0.221387 --> 0.220666).  Saving model ...\n",
      "Epoch: 56 \tTraining Loss: 0.221288 \tValidation Loss: 0.219843\n",
      "Validation loss decreased (0.220666 --> 0.219843).  Saving model ...\n",
      "Epoch: 57 \tTraining Loss: 0.220345 \tValidation Loss: 0.218897\n",
      "Validation loss decreased (0.219843 --> 0.218897).  Saving model ...\n",
      "Epoch: 58 \tTraining Loss: 0.219230 \tValidation Loss: 0.217801\n",
      "Validation loss decreased (0.218897 --> 0.217801).  Saving model ...\n",
      "Epoch: 59 \tTraining Loss: 0.217936 \tValidation Loss: 0.216550\n",
      "Validation loss decreased (0.217801 --> 0.216550).  Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 0.216406 \tValidation Loss: 0.215030\n",
      "Validation loss decreased (0.216550 --> 0.215030).  Saving model ...\n",
      "Epoch: 61 \tTraining Loss: 0.214617 \tValidation Loss: 0.213253\n",
      "Validation loss decreased (0.215030 --> 0.213253).  Saving model ...\n",
      "Epoch: 62 \tTraining Loss: 0.212543 \tValidation Loss: 0.211276\n",
      "Validation loss decreased (0.213253 --> 0.211276).  Saving model ...\n",
      "Epoch: 63 \tTraining Loss: 0.210256 \tValidation Loss: 0.209059\n",
      "Validation loss decreased (0.211276 --> 0.209059).  Saving model ...\n",
      "Epoch: 64 \tTraining Loss: 0.207833 \tValidation Loss: 0.206816\n",
      "Validation loss decreased (0.209059 --> 0.206816).  Saving model ...\n",
      "Epoch: 65 \tTraining Loss: 0.205403 \tValidation Loss: 0.204505\n",
      "Validation loss decreased (0.206816 --> 0.204505).  Saving model ...\n",
      "Epoch: 66 \tTraining Loss: 0.203059 \tValidation Loss: 0.202228\n",
      "Validation loss decreased (0.204505 --> 0.202228).  Saving model ...\n",
      "Epoch: 67 \tTraining Loss: 0.200781 \tValidation Loss: 0.200142\n",
      "Validation loss decreased (0.202228 --> 0.200142).  Saving model ...\n",
      "Epoch: 68 \tTraining Loss: 0.198716 \tValidation Loss: 0.198131\n",
      "Validation loss decreased (0.200142 --> 0.198131).  Saving model ...\n",
      "Epoch: 69 \tTraining Loss: 0.196796 \tValidation Loss: 0.196358\n",
      "Validation loss decreased (0.198131 --> 0.196358).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.195063 \tValidation Loss: 0.194768\n",
      "Validation loss decreased (0.196358 --> 0.194768).  Saving model ...\n",
      "Epoch: 71 \tTraining Loss: 0.193570 \tValidation Loss: 0.193400\n",
      "Validation loss decreased (0.194768 --> 0.193400).  Saving model ...\n",
      "Epoch: 72 \tTraining Loss: 0.192235 \tValidation Loss: 0.192128\n",
      "Validation loss decreased (0.193400 --> 0.192128).  Saving model ...\n",
      "Epoch: 73 \tTraining Loss: 0.191039 \tValidation Loss: 0.191015\n",
      "Validation loss decreased (0.192128 --> 0.191015).  Saving model ...\n",
      "Epoch: 74 \tTraining Loss: 0.190005 \tValidation Loss: 0.190013\n",
      "Validation loss decreased (0.191015 --> 0.190013).  Saving model ...\n",
      "Epoch: 75 \tTraining Loss: 0.189073 \tValidation Loss: 0.189138\n",
      "Validation loss decreased (0.190013 --> 0.189138).  Saving model ...\n",
      "Epoch: 76 \tTraining Loss: 0.188229 \tValidation Loss: 0.188318\n",
      "Validation loss decreased (0.189138 --> 0.188318).  Saving model ...\n",
      "Epoch: 77 \tTraining Loss: 0.187492 \tValidation Loss: 0.187618\n",
      "Validation loss decreased (0.188318 --> 0.187618).  Saving model ...\n",
      "Epoch: 78 \tTraining Loss: 0.186847 \tValidation Loss: 0.186956\n",
      "Validation loss decreased (0.187618 --> 0.186956).  Saving model ...\n",
      "Epoch: 79 \tTraining Loss: 0.186239 \tValidation Loss: 0.186404\n",
      "Validation loss decreased (0.186956 --> 0.186404).  Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.185707 \tValidation Loss: 0.185873\n",
      "Validation loss decreased (0.186404 --> 0.185873).  Saving model ...\n",
      "Epoch: 81 \tTraining Loss: 0.185223 \tValidation Loss: 0.185379\n",
      "Validation loss decreased (0.185873 --> 0.185379).  Saving model ...\n",
      "Epoch: 82 \tTraining Loss: 0.184792 \tValidation Loss: 0.184935\n",
      "Validation loss decreased (0.185379 --> 0.184935).  Saving model ...\n",
      "Epoch: 83 \tTraining Loss: 0.184380 \tValidation Loss: 0.184546\n",
      "Validation loss decreased (0.184935 --> 0.184546).  Saving model ...\n",
      "Epoch: 84 \tTraining Loss: 0.183993 \tValidation Loss: 0.184180\n",
      "Validation loss decreased (0.184546 --> 0.184180).  Saving model ...\n",
      "Epoch: 85 \tTraining Loss: 0.183658 \tValidation Loss: 0.183890\n",
      "Validation loss decreased (0.184180 --> 0.183890).  Saving model ...\n",
      "Epoch: 86 \tTraining Loss: 0.183338 \tValidation Loss: 0.183537\n",
      "Validation loss decreased (0.183890 --> 0.183537).  Saving model ...\n",
      "Epoch: 87 \tTraining Loss: 0.183025 \tValidation Loss: 0.183249\n",
      "Validation loss decreased (0.183537 --> 0.183249).  Saving model ...\n",
      "Epoch: 88 \tTraining Loss: 0.182757 \tValidation Loss: 0.182969\n",
      "Validation loss decreased (0.183249 --> 0.182969).  Saving model ...\n",
      "Epoch: 89 \tTraining Loss: 0.182484 \tValidation Loss: 0.182730\n",
      "Validation loss decreased (0.182969 --> 0.182730).  Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.182235 \tValidation Loss: 0.182456\n",
      "Validation loss decreased (0.182730 --> 0.182456).  Saving model ...\n",
      "Epoch: 91 \tTraining Loss: 0.182009 \tValidation Loss: 0.182234\n",
      "Validation loss decreased (0.182456 --> 0.182234).  Saving model ...\n",
      "Epoch: 92 \tTraining Loss: 0.181768 \tValidation Loss: 0.181987\n",
      "Validation loss decreased (0.182234 --> 0.181987).  Saving model ...\n",
      "Epoch: 93 \tTraining Loss: 0.181577 \tValidation Loss: 0.181826\n",
      "Validation loss decreased (0.181987 --> 0.181826).  Saving model ...\n",
      "Epoch: 94 \tTraining Loss: 0.181376 \tValidation Loss: 0.181597\n",
      "Validation loss decreased (0.181826 --> 0.181597).  Saving model ...\n",
      "Epoch: 95 \tTraining Loss: 0.181184 \tValidation Loss: 0.181435\n",
      "Validation loss decreased (0.181597 --> 0.181435).  Saving model ...\n",
      "Epoch: 96 \tTraining Loss: 0.181007 \tValidation Loss: 0.181236\n",
      "Validation loss decreased (0.181435 --> 0.181236).  Saving model ...\n",
      "Epoch: 97 \tTraining Loss: 0.180833 \tValidation Loss: 0.181095\n",
      "Validation loss decreased (0.181236 --> 0.181095).  Saving model ...\n",
      "Epoch: 98 \tTraining Loss: 0.180663 \tValidation Loss: 0.180924\n",
      "Validation loss decreased (0.181095 --> 0.180924).  Saving model ...\n",
      "Epoch: 99 \tTraining Loss: 0.180522 \tValidation Loss: 0.180752\n",
      "Validation loss decreased (0.180924 --> 0.180752).  Saving model ...\n",
      "Epoch: 100 \tTraining Loss: 0.180360 \tValidation Loss: 0.180600\n",
      "Validation loss decreased (0.180752 --> 0.180600).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = [], []\n",
    "\n",
    "valid_loss_min = np.Inf \n",
    "\n",
    "model.double()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Shuffle training set\n",
    "    num_train = len(X_train)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "    # Shuffle validation set\n",
    "    num_valid = len(X_valid)\n",
    "    indices = list(range(num_valid))\n",
    "    np.random.shuffle(indices)\n",
    "    X_valid = X_valid[indices]\n",
    "    y_valid = y_valid[indices]    \n",
    "        \n",
    "    train_loss = 0.0\n",
    "        \n",
    "    for i in range(N_batches):\n",
    "        \n",
    "        x, y = X_train[i*batch_size:(i+1)*batch_size, :], y_train[i*batch_size:(i+1)*batch_size, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_ = model(x)\n",
    "        loss = criterion(y, y_)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    \n",
    "    else:\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in zip(X_valid, y_valid):\n",
    "                \n",
    "                y_ = model(x)\n",
    "                loss = criterion(y, y_)\n",
    "                valid_loss += loss.item()\n",
    "            \n",
    "    train_losses.append(train_loss/N_batches)\n",
    "    valid_losses.append(valid_loss/len(X_valid)) \n",
    "        \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss/N_batches,\n",
    "        valid_loss/len(X_valid)\n",
    "        ))\n",
    "    \n",
    "    if valid_loss/len(X_valid) <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss/len(X_valid)))\n",
    "        torch.save(model.state_dict(), new_dir + '/' + model_name + f'/model_{epochs}_epochs.pt')\n",
    "        valid_loss_min = valid_loss/len(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "314a823c-87ea-40a2-b9b0-13ba4fa9a28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Графики\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.ylim(0.0, 0.5)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510605fc-d185-4ffd-993e-19cae9b401a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
